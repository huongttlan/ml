{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### First, read in the data first\n",
    "import gzip\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz', 'rb') as f:\n",
    "    file_content = f.read()   \n",
    "    \n",
    "nonspace = re.compile(r'\\S')\n",
    "def iterparse(j):\n",
    "    decoder = js.JSONDecoder()\n",
    "    pos = 0\n",
    "    while True:\n",
    "        matched = nonspace.search(j, pos)\n",
    "        if not matched:\n",
    "            break\n",
    "        pos = matched.start()\n",
    "        decoded, pos = decoder.raw_decode(j, pos)\n",
    "        yield decoded\n",
    "data_lst=list(iterparse(file_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "import simplejson as js\n",
    "import json \n",
    "import dill\n",
    "import re\n",
    "\n",
    "\n",
    "##### First, read in the data first\n",
    "import gzip\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz', 'rb') as f:\n",
    "    file_content = f.read()   \n",
    "    \n",
    "nonspace = re.compile(r'\\S')\n",
    "def iterparse(j):\n",
    "    decoder = js.JSONDecoder()\n",
    "    pos = 0\n",
    "    while True:\n",
    "        matched = nonspace.search(j, pos)\n",
    "        if not matched:\n",
    "            break\n",
    "        pos = matched.start()\n",
    "        decoded, pos = decoder.raw_decode(j, pos)\n",
    "        yield decoded\n",
    "data_lst=list(iterparse(file_content))\n",
    "#print data_lst[0]\n",
    "\n",
    "city=[]\n",
    "stars=[]\n",
    "categories=[]\n",
    "att=[]\n",
    "\n",
    "for item in data_lst:\n",
    "    city.append(item.get('city'))\n",
    "    categories.append(item.get('categories')) \n",
    "    att.append(item.get('attributes'))\n",
    "    stars.append(item.get('stars'))\n",
    "\n",
    "df=pd.DataFrame({'stars': stars})\n",
    " \n",
    "#Just get the list in the data:\n",
    "for x in data_lst:\n",
    "    del x['stars']\n",
    "    #del x['hours']    \n",
    "    # who cares for the hours\n",
    "    \n",
    "#####################################\n",
    "#####################################\n",
    "#Question 1: City model\n",
    "\n",
    "class Estimator(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__ (self):\n",
    "        self.averageByCity ={}\n",
    "    \n",
    "    def fit(self, df):\n",
    "        try:\n",
    "            self.averageByCity=df.groupby(by=['city'])['stars'].mean()\n",
    "        except:\n",
    "            self.averageByCity={}\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        try:\n",
    "            return float(self.averageByCity[X['city']])\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "# my feature data is a list of dictionaries with city; long; lat; cat stuffs\n",
    "# my y value is star rating \n",
    "class myCityModel(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__(self,y):\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        city = [{'city':x['city']} for x in X] \n",
    "        v = DictVectorizer(sparse=False)\n",
    "        retval = v.fit_transform(city)\n",
    "        return retval\n",
    "\n",
    "class myLongLatModel(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__(self,y):\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        retval = [[x['longitude'],x['latitude']] for x in X] \n",
    "        return retval\n",
    "    \n",
    "class myCatModel(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__(self,y):\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        def mylocalfun(x): \n",
    "            return {y:1 for y in x}\n",
    "                \n",
    "        categories = [x['categories'] for x in X]\n",
    "        categories = map(mylocalfun, categories)\n",
    "        v = DictVectorizer(sparse=False)\n",
    "        retval = v.fit_transform(categories)\n",
    "        return retval\n",
    "\n",
    "def myFlatterLocal(u,v):\n",
    "    if type(v) == list:\n",
    "        v = { z:1 for z in v}\n",
    "    if type(v) == dict:\n",
    "        retVal = v.values()\n",
    "        retKey = [re.sub(' ','', u +\"_\"+x) for x in v.keys()]\n",
    "        retPair = {x:y for x,y in zip(retKey, retVal)}\n",
    "    else:\n",
    "        retPair = {u:v}\n",
    "    return retPair\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "def myFlatter(myTestData):\n",
    "    if(len(myTestData)==0):\n",
    "        return {}\n",
    "    retval = []\n",
    "    for myKey in myTestData.keys():\n",
    "        retval.append(myFlatterLocal(myKey, myTestData[myKey]))\n",
    "    retval = reduce(merge_two_dicts,retval)\n",
    "    return retval\n",
    "\n",
    "\n",
    "class myAttModel(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__(self,y):\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        tmp = [x['attributes'] for x in X]\n",
    "        attributes= map(myFlatter, tmp)\n",
    "        v = DictVectorizer(sparse=False)\n",
    "        retval = v.fit_transform(attributes)\n",
    "        return retval\n",
    "    \n",
    "tmpModel1 = myCityModel(y=stars)\n",
    "output = tmpModel.transform(data_lst)    \n",
    "\n",
    "tmpModel2 = myLongLatModel(y=stars)\n",
    "output2 = tmpModel2.transform(data_lst)\n",
    "output2\n",
    "\n",
    "tmpModel3 = myCatModel(y=stars)\n",
    "output3 = tmpModel3.transform(data_lst)\n",
    "output3\n",
    "\n",
    "tmpModel4 = myAttModel(y=stars)\n",
    "output4 = tmpModel4.transform(data_lst)\n",
    "output4\n",
    "\n",
    "\n",
    "combined_features = FeatureUnion([('city',tmpModel1),('longlat',tmpModel2),\\\n",
    "                                    ('categories',tmpModel3), ('attributes',tmpModel4)])\n",
    "\n",
    "X_features = combined_features.fit(data_lst,stars).transform(data_lst)\n",
    "\n",
    "class kEstimator(sklearn.base.BaseEstimator, sklearn.base.RegressorMixin):\n",
    "    def __init__ (self):\n",
    "        self.neigh=KNeighborsRegressor(n_neighbors=5)\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        self.neigh.fit(X, y) \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        try:\n",
    "            return self.neigh.predict(X)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "stars = np.array(stars)\n",
    "\n",
    "q5 = kEstimator()  # initialize\n",
    "#df=pd.DataFrame({'stars': stars})\n",
    "#Ysubset_np=df[['stars']].as_matrix()\n",
    "q5.fit(X_features,stars) \n",
    "\n",
    "\n",
    "#test={u'city': u'Apache Junction', u'review_count': 3, u'name': u'Brown Bear BBQ', u'neighborhoods': [], u'open': True, u'business_id': u'ElEF5b3n27IBzbA4R-1M1g', u'full_address': u'Chevron\\n3940 S Ironwood Dr\\nApache Junction, AZ 85120', u'hours': {u'Tuesday': {u'close': u'19:00', u'open': u'07:00'}, u'Friday': {u'close': u'19:00', u'open': u'07:00'}, u'Monday': {u'close': u'19:00', u'open': u'07:00'}, u'Thursday': {u'close': u'19:00', u'open': u'07:00'}, u'Wednesday': {u'close': u'19:00', u'open': u'07:00'}}, u'state': u'AZ', u'longitude': -111.564202, u'latitude': 33.379277, u'attributes': {u'Take-out': True, u'Parking': {u'garage': False, u'street': False, u'validated': False, u'lot': False, u'valet': False}, u'Good For': {u'dessert': False, u'latenight': False, u'lunch': False, u'dinner': False, u'breakfast': False, u'brunch': False}, u'Attire': u'casual', u'Waiter Service': False, u'Takes Reservations': False, u'Accepts Credit Cards': True, u'Price Range': 2}, u'type': u'business', u'categories': [u'Food', u'Street Vendors', u'Barbeque', u'Restaurants']}\n",
    "#test1=test1.keys\n",
    "# df1=pd.DataFrame({'city': city, 'stars': stars})\n",
    "# q1_data=df1.groupby(by=['city'])['stars'].mean()\n",
    "# q1_city=q1_data.to_dict().keys()\n",
    "\n",
    "# q1_v = DictVectorizer(sparse=False)\n",
    "# q1_v.fit_transform(cityDict)\n",
    "\n",
    "# f=open(\"dict_city_model\",\"wb\")\n",
    "# dill.dump(q1_v, f)\n",
    "# f.close()\n",
    "\n",
    "# q1_test={'city': \"New York\"}\n",
    "# q1_test1=q1_v.transform(q1_test)\n",
    "# print q1_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'By Appointment Only': True}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst[0]['attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "        -111.983758 ,   33.499313 ],\n",
       "       [   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "         -89.335844 ,   43.238893 ],\n",
       "       [   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "         -89.353437 ,   43.252267 ],\n",
       "       ..., \n",
       "       [   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "        -112.071074 ,   33.4571063],\n",
       "       [   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "        -112.064508 ,   33.5313101],\n",
       "       [   0.       ,    0.       ,    0.       , ...,    0.       ,\n",
       "          -3.2025293,   55.9441696]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = data_lst[0]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Doctors': 1, 'Health & Medical': 1}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:1 for x in tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-111.983758"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst[0]['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
